
services:
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181" # Expose náº¿u cáº§n truy cáº­p bÃªn ngoÃ i


  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    environment:
      - KAFKA_BROKER_ID=1
      # ðŸ”¥ Listeners: both PLAINTEXT and PLAINTEXT_HOST!
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      # ðŸ”¥ Advertise them
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
    ports:
      - "9092:9092"    # Kafka inside Docker network
      - "29092:29092"  # Kafka exposed to localhost (outside Docker)
    depends_on:
      - zookeeper         


      


  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077" # Spark master port
      - "8080:8080" # Spark master UI
    volumes:
      - ./ProcessingData/customer/ETL.py:/opt/bitnami/spark/jobs/custETL.py 
      - ./ProcessingData/product/ETL.py:/opt/bitnami/spark/jobs/productETL.py
      - ./ProcessingData/sales/ETL.py:/opt/bitnami/spark/jobs/salesETL.py 
      - ./postgresql.jar:/opt/bitnami/spark/jars/postgresql.jar


  spark-worker-1:
    image: bitnami/spark:latest
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"  # UI port, nÃªn khÃ¡c nhau náº¿u má»Ÿ bÃªn ngoÃ i

  spark-worker-2:
    image: bitnami/spark:latest
    container_name: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=1
    depends_on:
      - spark-master
    ports:
      - "8082:8081"  # UI port khÃ¡c nhau náº¿u expose

  spark-worker-3:
    image: bitnami/spark:latest
    container_name: spark-worker-3
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=1
    depends_on:
      - spark-master
    ports:
      - "8083:8081"  # UI port khÃ¡c nhau náº¿u expose



  db:
    image: postgres
    container_name: postgres-db
    restart: always
    shm_size: 128mb
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: example
      POSTGRES_DB: mydatabase
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql

  # python-producer:
  #   image: python:3.10-slim
  #   build: 
  #     context: Streaming/python-init/. 
  #   container_name: python-producer
  #   volumes:
  #     - ./testAPI.py:/app/testAPI.py
  #     - ./datasetIngestion.py:/app/datasetIngestion.py
  #   working_dir: /app
  #   depends_on:
  #     - kafka
  #   command: python /app/datasetIngestion.py




volumes:
  postgres-data:
