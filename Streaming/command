
docker compose up -d 




# run this first 
docker exec -it kafka kafka-topics.sh --create --topic customer-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
docker exec -it kafka kafka-topics.sh --create --topic product-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
docker exec -it kafka kafka-topics.sh --create --topic sales-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
docker exec -it kafka kafka-console-consumer.sh --topic product-topic --bootstrap-server localhost:9092



# spark master container 
docker exec -it spark-master /bin/bash
spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 \
  --jars /opt/bitnami/spark/jars/postgresql.jar \
  --total-executor-cores 1  \
  /opt/bitnami/spark/jobs/weatherETL.py






# connect to posgre db
docker exec -it postgres-db psql -U user -d mydatabase
\c mydatabase #\c connect to mydatabase